{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vjqzYMnyaa6"
   },
   "source": [
    "# Prepare Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "f9punhWoKANy",
    "outputId": "9c81a567-a2d1-4a01-ddae-dcd380e19f2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l\r",
      "\u001b[K     |▎                               | 10kB 23.6MB/s eta 0:00:01\r",
      "\u001b[K     |▋                               | 20kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |█                               | 30kB 4.6MB/s eta 0:00:01\r",
      "\u001b[K     |█▎                              | 40kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |█▋                              | 51kB 3.6MB/s eta 0:00:01\r",
      "\u001b[K     |██                              | 61kB 4.3MB/s eta 0:00:01\r",
      "\u001b[K     |██▎                             | 71kB 4.9MB/s eta 0:00:01\r",
      "\u001b[K     |██▋                             | 81kB 5.5MB/s eta 0:00:01\r",
      "\u001b[K     |███                             | 92kB 6.1MB/s eta 0:00:01\r",
      "\u001b[K     |███▎                            | 102kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███▋                            | 112kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████                            | 122kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▎                           | 133kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████▋                           | 143kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████                           | 153kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 163kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████▋                          | 174kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████                          | 184kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▎                         | 194kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▋                         | 204kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████                         | 215kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▎                        | 225kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████▋                        | 235kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 245kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▎                       | 256kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████▋                       | 266kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████                       | 276kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▎                      | 286kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▋                      | 296kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████                      | 307kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▎                     | 317kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 327kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████                     | 337kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▎                    | 348kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▋                    | 358kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████                    | 368kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▎                   | 378kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████▋                   | 389kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 399kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 409kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▋                  | 419kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████                  | 430kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▎                 | 440kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████▋                 | 450kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 460kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 471kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▋                | 481kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████                | 491kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▎               | 501kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▋               | 512kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████               | 522kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▎              | 532kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████▋              | 542kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████              | 552kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▎             | 563kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▋             | 573kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████             | 583kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▎            | 593kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▋            | 604kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████            | 614kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▎           | 624kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▋           | 634kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████           | 645kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▎          | 655kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▋          | 665kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████          | 675kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 686kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 696kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████         | 706kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▎        | 716kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▋        | 727kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████        | 737kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▎       | 747kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▋       | 757kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████▉       | 768kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▏      | 778kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 788kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 798kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▏     | 808kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 819kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▉     | 829kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▏    | 839kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▌    | 849kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 860kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▏   | 870kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▌   | 880kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████▉   | 890kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 901kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▌  | 911kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▉  | 921kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 931kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▌ | 942kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▉ | 952kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▏| 962kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▌| 972kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▉| 983kB 4.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 993kB 4.8MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Code to download file into Colaboratory:\n",
    "!pip install -U -q PyDrive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "# Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)\n",
    "\n",
    "id = '1ZZ_xgbVMEVuX6NxvpFIk8fWwl5rrvKh0'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('train.tar.gz')\n",
    "\n",
    "id = '1cLKpcZS-P9TCLO0X1xw2p5ZLIwPuzErM'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('test.tar.gz')\n",
    "\n",
    "id = '11opV9N2wI4rcpv5QcsNY2clVgN-IWA7_'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('train.txt')\n",
    "\n",
    "id = '1JcC-B4MDgW52YW-OYdK4s-xrM6rKfI54'\n",
    "downloaded = drive.CreateFile({'id':id}) \n",
    "downloaded.GetContentFile('densenet121_epoch_12_val_loss_0.1205.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rGSecs31MFa_"
   },
   "outputs": [],
   "source": [
    "# Unzip tar.gz\n",
    "\n",
    "import tarfile\n",
    "\n",
    "def un_tar(file_name):\n",
    "       # untar zip file\"\"\"\n",
    "    tar = tarfile.open(file_name)\n",
    "    names = tar.getnames()\n",
    "    tar.extractall()\n",
    "    tar.close()\n",
    "    \n",
    "un_tar('test.tar.gz')\n",
    "un_tar(\"train.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "DMPr1100OFMI",
    "outputId": "af720d1c-7d13-4075-d938-67d6f93e94e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31925\n",
      "15516\n"
     ]
    }
   ],
   "source": [
    "# Check the image loaded\n",
    "\n",
    "import os\n",
    "train_path = \"train2014\"\n",
    "test_path = \"val2014\"\n",
    "\n",
    "print(len(os.listdir(\"train2014\")))\n",
    "print(len(os.listdir(\"val2014\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y6gxR5JJ6c9I"
   },
   "source": [
    "# Data Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ogybB1EOOVso"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.densenet import DenseNet121, preprocess_input\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, BatchNormalization, Dropout, Activation\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "XEwl8TpOcSaj",
    "outputId": "aeec5b44-1863-465c-f7a0-d1ab66170714"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Label processing\n",
    "\n",
    "import pandas as pd \n",
    "from pandas.core.frame import DataFrame\n",
    "data = pd.read_table('train.txt',sep='\\t',header=None)    \n",
    "\n",
    "img_list_raw = data[0].tolist()\n",
    "img_list = []\n",
    "for i in img_list_raw:\n",
    "    img_list.append(train_path + '/' + i)\n",
    "\n",
    "label_list_raw = data[1].tolist()\n",
    "label_list = []\n",
    "\n",
    "def process_label(label_str):\n",
    "    label_int = []\n",
    "    for x in label_str.split(','):\n",
    "        label_int.append((int(x)))\n",
    "    return label_int\n",
    "\n",
    "for ll in label_list_raw:\n",
    "    label_list.append(process_label(ll))\n",
    "\n",
    "dic =  {\"filename\": img_list, \"label\": label_list}\n",
    "df = DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "HT2u5NnZwf9P",
    "outputId": "9e1dbbd5-8c77-4480-98be-ef3b1b807682"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          filename     label\n",
      "0  train2014/0.jpg  [13, 18]\n",
      "1  train2014/1.jpg      [19]\n",
      "2  train2014/2.jpg      [10]\n",
      "3  train2014/3.jpg       [2]\n",
      "4  train2014/4.jpg    [8, 7]\n",
      "5  train2014/5.jpg      [19]\n",
      "6  train2014/6.jpg       [0]\n",
      "7  train2014/7.jpg      [19]\n",
      "8  train2014/8.jpg  [18, 19]\n",
      "9  train2014/9.jpg       [8]\n"
     ]
    }
   ],
   "source": [
    "print(df[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "pTixeNvHjd97",
    "outputId": "591230a7-926e-4bbd-ba6a-ab148df03429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 27000 images belonging to 20 classes.\n",
      "Found 3000 images belonging to 20 classes.\n",
      "Found 1925 images.\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# Image pre-processing and generators\n",
    "\n",
    "IMAGE_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(horizontal_flip=True,\n",
    "                                    preprocessing_function=preprocess_input,\n",
    "                                    rescale=1. / 255,\n",
    "                                    rotation_range=5,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.1,\n",
    "                                    zoom_range=0.1\n",
    "                                   )\n",
    "\n",
    "val_datagen = ImageDataGenerator(horizontal_flip=True,                                 \n",
    "                                    preprocessing_function=preprocess_input,\n",
    "                                    rescale=1. / 255,\n",
    "                                    rotation_range=5,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.1,\n",
    "                                    zoom_range=0.1\n",
    "                                  )\n",
    "\n",
    "test_datagen = ImageDataGenerator(horizontal_flip=True,                                 \n",
    "                                    preprocessing_function=preprocess_input,\n",
    "                                    rescale=1. / 255,\n",
    "                                    rotation_range=5,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.1,\n",
    "                                    zoom_range=0.1\n",
    "                                  )\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe = df[: 27000],\n",
    "                                                     x_col='filename', y_col='label', target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                                     class_mode='categorical', \n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     seed=42,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(dataframe = df[27000: 30000],\n",
    "                                                     x_col='filename', y_col='label', target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                                     class_mode='categorical', \n",
    "                                                     batch_size=BATCH_SIZE,\n",
    "                                                     seed=42,\n",
    "                                                     shuffle=True)\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe = df[30000: ],\n",
    "                                                     x_col='filename', target_size=(IMAGE_SIZE, IMAGE_SIZE), \n",
    "                                                     class_mode=None,\n",
    "                                                     batch_size=1,\n",
    "                                                     seed=42,\n",
    "                                                     shuffle=False)\n",
    "num_classes = len(train_generator.class_indices)\n",
    "print(num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsihiHSrUs3G"
   },
   "source": [
    "# Build, Train, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 16429
    },
    "colab_type": "code",
    "id": "oeq_PnVNzoy-",
    "outputId": "7f279676-f3cd-46a7-b6c5-d89fc3e3f430"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Downloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "29089792/29084464 [==============================] - 1s 0us/step\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d (ZeroPadding2D)  (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 112, 112, 64) 9408        zero_padding2d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalizationV1) (None, 112, 112, 64) 256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 112, 112, 64) 0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 114, 114, 64) 0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 56, 56, 64)   0           zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 56, 56, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 56, 56, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 56, 56, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 56, 56, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 56, 56, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 56, 56, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 56, 56, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 56, 56, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 56, 56, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 56, 56, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 56, 56, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 56, 56, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 56, 56, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 56, 56, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 56, 56, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 56, 56, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 56, 56, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 56, 56, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 56, 56, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 56, 56, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 56, 56, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 56, 56, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 56, 56, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 56, 56, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalizationV1) (None, 56, 56, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 56, 56, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 56, 56, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 28, 28, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 28, 28, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 28, 28, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 28, 28, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 28, 28, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 28, 28, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 28, 28, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 28, 28, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 28, 28, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 28, 28, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 28, 28, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 28, 28, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 28, 28, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 28, 28, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 28, 28, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 28, 28, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 28, 28, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 28, 28, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 28, 28, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 28, 28, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 28, 28, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 28, 28, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 28, 28, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 28, 28, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 28, 28, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 28, 28, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 28, 28, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 28, 28, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 28, 28, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 28, 28, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 28, 28, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 28, 28, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 28, 28, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 28, 28, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 28, 28, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 28, 28, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 28, 28, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 28, 28, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 28, 28, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 28, 28, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 28, 28, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 28, 28, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 28, 28, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 28, 28, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 28, 28, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 28, 28, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 28, 28, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 28, 28, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 28, 28, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 28, 28, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 28, 28, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 28, 28, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 28, 28, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalizationV1) (None, 28, 28, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 28, 28, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 28, 28, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 14, 14, 256)  0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 256)  1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 14, 14, 256)  0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 128)  32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 128)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 14, 14, 288)  0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 14, 14, 288)  1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 14, 14, 288)  0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 128)  36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 128)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 14, 14, 320)  0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 14, 14, 320)  1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 14, 14, 320)  0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 128)  40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 128)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 14, 14, 352)  0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 14, 14, 352)  1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 14, 14, 352)  0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 128)  45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 128)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 14, 14, 384)  0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 14, 14, 384)  1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 14, 14, 384)  0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 128)  49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 128)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 14, 14, 416)  0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 14, 14, 416)  1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 14, 14, 416)  0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 128)  53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 128)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 14, 14, 448)  0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 14, 14, 448)  1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 14, 14, 448)  0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 128)  57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 128)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 14, 14, 480)  0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 14, 14, 480)  1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 14, 14, 480)  0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 128)  61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 128)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 14, 14, 512)  0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 14, 14, 512)  2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 14, 14, 512)  0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 128)  65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 128)  512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 128)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 32)   36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 14, 14, 544)  0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 14, 14, 544)  2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 14, 14, 544)  0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 128)  69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 14, 14, 576)  0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 14, 14, 576)  2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 14, 14, 576)  0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 128)  73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 14, 14, 608)  0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 14, 14, 608)  2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 14, 14, 608)  0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 128)  77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 14, 14, 640)  0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 14, 14, 640)  2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 14, 14, 640)  0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 128)  81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 14, 14, 672)  0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 14, 14, 672)  2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 14, 14, 672)  0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 128)  86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 14, 14, 704)  0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 14, 14, 704)  2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 14, 14, 704)  0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 128)  90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 14, 14, 736)  0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 14, 14, 736)  2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 14, 14, 736)  0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 128)  94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 14, 14, 768)  0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 14, 14, 768)  3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 14, 14, 768)  0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 128)  98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 14, 14, 800)  0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 14, 14, 800)  3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 14, 14, 800)  0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 128)  102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 14, 14, 832)  0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 14, 14, 832)  3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 14, 14, 832)  0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 128)  106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 14, 14, 864)  0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 14, 14, 864)  3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 14, 14, 864)  0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 128)  110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 14, 14, 896)  0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 14, 14, 896)  3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 14, 14, 896)  0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 128)  114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 14, 14, 928)  0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 14, 14, 928)  3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 14, 14, 928)  0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 128)  118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 14, 14, 960)  0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 14, 14, 960)  3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 14, 14, 960)  0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 128)  122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 14, 14, 992)  0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 14, 14, 992)  3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 14, 14, 992)  0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 14, 14, 128)  126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 14, 14, 128)  512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 14, 14, 128)  0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 14, 14, 32)   36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 14, 14, 1024) 0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalizationV1) (None, 14, 14, 1024) 4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 14, 14, 1024) 0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 14, 14, 512)  524288      pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 7, 7, 512)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 512)    2048        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 7, 7, 512)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 128)    65536       conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 128)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_concat (Concatenat (None, 7, 7, 544)    0           pool4_pool[0][0]                 \n",
      "                                                                 conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_bn (BatchNormali (None, 7, 7, 544)    2176        conv5_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_0_relu (Activation (None, 7, 7, 544)    0           conv5_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 128)    69632       conv5_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 128)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_concat (Concatenat (None, 7, 7, 576)    0           conv5_block1_concat[0][0]        \n",
      "                                                                 conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_bn (BatchNormali (None, 7, 7, 576)    2304        conv5_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_0_relu (Activation (None, 7, 7, 576)    0           conv5_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 128)    73728       conv5_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 128)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_concat (Concatenat (None, 7, 7, 608)    0           conv5_block2_concat[0][0]        \n",
      "                                                                 conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_bn (BatchNormali (None, 7, 7, 608)    2432        conv5_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_0_relu (Activation (None, 7, 7, 608)    0           conv5_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_conv (Conv2D)    (None, 7, 7, 128)    77824       conv5_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_1_relu (Activation (None, 7, 7, 128)    0           conv5_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block4_concat (Concatenat (None, 7, 7, 640)    0           conv5_block3_concat[0][0]        \n",
      "                                                                 conv5_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_bn (BatchNormali (None, 7, 7, 640)    2560        conv5_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_0_relu (Activation (None, 7, 7, 640)    0           conv5_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_conv (Conv2D)    (None, 7, 7, 128)    81920       conv5_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_1_relu (Activation (None, 7, 7, 128)    0           conv5_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block5_concat (Concatenat (None, 7, 7, 672)    0           conv5_block4_concat[0][0]        \n",
      "                                                                 conv5_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_bn (BatchNormali (None, 7, 7, 672)    2688        conv5_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_0_relu (Activation (None, 7, 7, 672)    0           conv5_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_conv (Conv2D)    (None, 7, 7, 128)    86016       conv5_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_1_relu (Activation (None, 7, 7, 128)    0           conv5_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block6_concat (Concatenat (None, 7, 7, 704)    0           conv5_block5_concat[0][0]        \n",
      "                                                                 conv5_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_bn (BatchNormali (None, 7, 7, 704)    2816        conv5_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_0_relu (Activation (None, 7, 7, 704)    0           conv5_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_conv (Conv2D)    (None, 7, 7, 128)    90112       conv5_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_1_relu (Activation (None, 7, 7, 128)    0           conv5_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block7_concat (Concatenat (None, 7, 7, 736)    0           conv5_block6_concat[0][0]        \n",
      "                                                                 conv5_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_bn (BatchNormali (None, 7, 7, 736)    2944        conv5_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_0_relu (Activation (None, 7, 7, 736)    0           conv5_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_conv (Conv2D)    (None, 7, 7, 128)    94208       conv5_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_1_relu (Activation (None, 7, 7, 128)    0           conv5_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block8_concat (Concatenat (None, 7, 7, 768)    0           conv5_block7_concat[0][0]        \n",
      "                                                                 conv5_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_bn (BatchNormali (None, 7, 7, 768)    3072        conv5_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_0_relu (Activation (None, 7, 7, 768)    0           conv5_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_conv (Conv2D)    (None, 7, 7, 128)    98304       conv5_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_bn (BatchNormali (None, 7, 7, 128)    512         conv5_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_1_relu (Activation (None, 7, 7, 128)    0           conv5_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_2_conv (Conv2D)    (None, 7, 7, 32)     36864       conv5_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block9_concat (Concatenat (None, 7, 7, 800)    0           conv5_block8_concat[0][0]        \n",
      "                                                                 conv5_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_bn (BatchNormal (None, 7, 7, 800)    3200        conv5_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_0_relu (Activatio (None, 7, 7, 800)    0           conv5_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_conv (Conv2D)   (None, 7, 7, 128)    102400      conv5_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block10_concat (Concatena (None, 7, 7, 832)    0           conv5_block9_concat[0][0]        \n",
      "                                                                 conv5_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_bn (BatchNormal (None, 7, 7, 832)    3328        conv5_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_0_relu (Activatio (None, 7, 7, 832)    0           conv5_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_conv (Conv2D)   (None, 7, 7, 128)    106496      conv5_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block11_concat (Concatena (None, 7, 7, 864)    0           conv5_block10_concat[0][0]       \n",
      "                                                                 conv5_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_bn (BatchNormal (None, 7, 7, 864)    3456        conv5_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_0_relu (Activatio (None, 7, 7, 864)    0           conv5_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_conv (Conv2D)   (None, 7, 7, 128)    110592      conv5_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block12_concat (Concatena (None, 7, 7, 896)    0           conv5_block11_concat[0][0]       \n",
      "                                                                 conv5_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_bn (BatchNormal (None, 7, 7, 896)    3584        conv5_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_0_relu (Activatio (None, 7, 7, 896)    0           conv5_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_conv (Conv2D)   (None, 7, 7, 128)    114688      conv5_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block13_concat (Concatena (None, 7, 7, 928)    0           conv5_block12_concat[0][0]       \n",
      "                                                                 conv5_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_bn (BatchNormal (None, 7, 7, 928)    3712        conv5_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_0_relu (Activatio (None, 7, 7, 928)    0           conv5_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_conv (Conv2D)   (None, 7, 7, 128)    118784      conv5_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block14_concat (Concatena (None, 7, 7, 960)    0           conv5_block13_concat[0][0]       \n",
      "                                                                 conv5_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_bn (BatchNormal (None, 7, 7, 960)    3840        conv5_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_0_relu (Activatio (None, 7, 7, 960)    0           conv5_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_conv (Conv2D)   (None, 7, 7, 128)    122880      conv5_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block15_concat (Concatena (None, 7, 7, 992)    0           conv5_block14_concat[0][0]       \n",
      "                                                                 conv5_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_bn (BatchNormal (None, 7, 7, 992)    3968        conv5_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_0_relu (Activatio (None, 7, 7, 992)    0           conv5_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_conv (Conv2D)   (None, 7, 7, 128)    126976      conv5_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_bn (BatchNormal (None, 7, 7, 128)    512         conv5_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_1_relu (Activatio (None, 7, 7, 128)    0           conv5_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_2_conv (Conv2D)   (None, 7, 7, 32)     36864       conv5_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block16_concat (Concatena (None, 7, 7, 1024)   0           conv5_block15_concat[0][0]       \n",
      "                                                                 conv5_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "bn (BatchNormalizationV1)       (None, 7, 7, 1024)   4096        conv5_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "relu (Activation)               (None, 7, 7, 1024)   0           bn[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1024)         0           relu[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           global_average_pooling2d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          524800      dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1 (BatchNo (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation (Activation)         (None, 512)          0           batch_normalization_v1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           activation[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          131328      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_v1_1 (Batch (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 256)          0           batch_normalization_v1_1[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 20)           5140        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,701,844\n",
      "Trainable params: 7,616,660\n",
      "Non-trainable params: 85,184\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build model\n",
    "\n",
    "base_model = DenseNet121(include_top=False, weights='imagenet', input_shape=(224,224,3), classes=20)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512,kernel_regularizer=regularizers.l2(l=0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256,kernel_regularizer=regularizers.l2(l=0.001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Activation('relu')(x)\n",
    "\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(20, activation='sigmoid')(x)\n",
    "\n",
    "    \n",
    "custom_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "base_model.trainable = False\n",
    "\n",
    "custom_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cA2Yj9W7g_mT"
   },
   "outputs": [],
   "source": [
    "# Compile the model and Callback functions \n",
    "\n",
    "custom_model.compile(optimizers.RMSprop(lr=0.0001, decay=1e-6),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, verbose=1, min_delta=1e-4)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, min_delta=1e-4)\n",
    "callbacks_list = [early_stop, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "colab_type": "code",
    "id": "7X97wVqBnJFZ",
    "outputId": "959d8224-f3ea-4a0f-f313-9460eafd7486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/12\n",
      "94/94 [==============================] - 52s 553ms/step - loss: 0.6108 - acc: 0.9438\n",
      "844/844 [==============================] - 800s 948ms/step - loss: 0.9284 - acc: 0.8840 - val_loss: 0.6108 - val_acc: 0.9438\n",
      "Epoch 2/12\n",
      "94/94 [==============================] - 51s 543ms/step - loss: 0.3789 - acc: 0.9557\n",
      "844/844 [==============================] - 778s 922ms/step - loss: 0.4913 - acc: 0.9474 - val_loss: 0.3789 - val_acc: 0.9557\n",
      "Epoch 3/12\n",
      "94/94 [==============================] - 51s 543ms/step - loss: 0.2642 - acc: 0.9578\n",
      "844/844 [==============================] - 778s 921ms/step - loss: 0.3254 - acc: 0.9537 - val_loss: 0.2642 - val_acc: 0.9578\n",
      "Epoch 4/12\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.2047 - acc: 0.9597\n",
      "844/844 [==============================] - 778s 921ms/step - loss: 0.2377 - acc: 0.9574 - val_loss: 0.2047 - val_acc: 0.9597\n",
      "Epoch 5/12\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 0.1771 - acc: 0.9606\n",
      "844/844 [==============================] - 777s 920ms/step - loss: 0.1877 - acc: 0.9599 - val_loss: 0.1771 - val_acc: 0.9606\n",
      "Epoch 6/12\n",
      "94/94 [==============================] - 51s 541ms/step - loss: 0.1666 - acc: 0.9581\n",
      "844/844 [==============================] - 776s 920ms/step - loss: 0.1576 - acc: 0.9623 - val_loss: 0.1666 - val_acc: 0.9581\n",
      "Epoch 7/12\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 0.1418 - acc: 0.9608\n",
      "844/844 [==============================] - 777s 920ms/step - loss: 0.1376 - acc: 0.9642 - val_loss: 0.1418 - val_acc: 0.9608\n",
      "Epoch 8/12\n",
      "94/94 [==============================] - 51s 544ms/step - loss: 0.1454 - acc: 0.9593\n",
      "844/844 [==============================] - 777s 920ms/step - loss: 0.1258 - acc: 0.9653 - val_loss: 0.1454 - val_acc: 0.9593\n",
      "Epoch 9/12\n",
      "94/94 [==============================] - 51s 542ms/step - loss: 0.1360 - acc: 0.9606\n",
      "844/844 [==============================] - 777s 921ms/step - loss: 0.1157 - acc: 0.9667 - val_loss: 0.1360 - val_acc: 0.9606\n",
      "Epoch 10/12\n",
      "94/94 [==============================] - 51s 545ms/step - loss: 0.1335 - acc: 0.9603\n",
      "844/844 [==============================] - 779s 922ms/step - loss: 0.1090 - acc: 0.9682 - val_loss: 0.1335 - val_acc: 0.9603\n",
      "Epoch 11/12\n",
      "94/94 [==============================] - 52s 551ms/step - loss: 0.1383 - acc: 0.9617\n",
      "844/844 [==============================] - 781s 926ms/step - loss: 0.1042 - acc: 0.9690 - val_loss: 0.1383 - val_acc: 0.9617\n",
      "Epoch 12/12\n",
      "94/94 [==============================] - 52s 553ms/step - loss: 0.1467 - acc: 0.9600\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "844/844 [==============================] - 783s 928ms/step - loss: 0.1001 - acc: 0.9697 - val_loss: 0.1467 - val_acc: 0.9600\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n // train_generator.batch_size\n",
    "STEP_SIZE_VALID=val_generator.n // val_generator.batch_size\n",
    "model_history = custom_model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=12,\n",
    "                    callbacks=callbacks_list\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 683
    },
    "colab_type": "code",
    "id": "qCDgr3jZtGKn",
    "outputId": "2c966965-ecbb-4190-b7cb-56f614a751d2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbVMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAGDCAYAAAAyM4nNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Accuracy and loss plot\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(model_history.history['acc'],'r')\n",
    "plt.plot(model_history.history['val_acc'],'g')\n",
    "plt.xticks(np.arange(0, 12, 1.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    "plt.figure(1)\n",
    "plt.plot(model_history.history['loss'],'r')\n",
    "plt.plot(model_history.history['val_loss'],'g')\n",
    "plt.xticks(np.arange(0, 12, 1.0))\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vwNywaEwMmzj",
    "outputId": "fe79f909-c8aa-431e-ace4-4addee11a5c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.12054033846931254, 0.96418333]"
      ]
     },
     "execution_count": 36,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.evaluate_generator(generator=val_generator,\n",
    "steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XdaaI7AAsbPA"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "custom_model.save('densenet121_epoch_12_val_loss_0.1205.h5')\n",
    "custom_model.save_weights('densenet121_epoch:12_val_loss_0.1205_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nwxf79ZdzueA",
    "outputId": "13fda4dc-6c9a-48d2-d494-c436c6b3fb3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1925/1925 [==============================] - 64s 33ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction for testing set\n",
    "STEP_SIZE_TEST=test_generator.n // test_generator.batch_size\n",
    "test_generator.reset()\n",
    "pred=custom_model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "id": "eeSoL8g40PuV",
    "outputId": "23e7178a-9186-459a-8416-c3558dbc6bae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7516883116883117\n",
      "              Filename  Predictions\n",
      "0  train2014/30000.jpg           19\n",
      "1  train2014/30001.jpg            2\n",
      "2  train2014/30002.jpg           18\n",
      "3  train2014/30003.jpg            2\n",
      "4  train2014/30004.jpg           16\n",
      "5  train2014/30005.jpg           14\n",
      "6  train2014/30006.jpg           18\n",
      "7  train2014/30007.jpg           19\n",
      "8  train2014/30008.jpg            6\n",
      "9  train2014/30009.jpg           17\n",
      "              Filename Predictions\n",
      "0  train2014/30000.jpg          19\n",
      "1  train2014/30001.jpg           2\n",
      "2  train2014/30002.jpg       18,19\n",
      "3  train2014/30003.jpg           2\n",
      "4  train2014/30004.jpg      8,9,16\n",
      "5  train2014/30005.jpg          14\n",
      "6  train2014/30006.jpg          18\n",
      "7  train2014/30007.jpg        9,19\n",
      "8  train2014/30008.jpg           6\n",
      "9  train2014/30009.jpg          17\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the accuracy on test set\n",
    "pred_bool = (pred >0.3)\n",
    "\n",
    "one_predictions = []\n",
    "\n",
    "predictions=[]\n",
    "labels = train_generator.class_indices\n",
    "# print(labels)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "\n",
    "################\n",
    "# Top1 Accuracy    #\n",
    "################\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    imax = np.argmax(pred[i])\n",
    "    pred_bool[i][imax] = True    \n",
    "\n",
    "for row in pred:\n",
    "    a = np.argmax(row)\n",
    "    one_predictions.append(labels[a])\n",
    "    \n",
    "c = 0\n",
    "test_labels = label_list[30000:]\n",
    "for i in range(len(test_labels)):\n",
    "    if one_predictions[i] in test_labels[i]:\n",
    "        c += 1\n",
    "print(c/len(test_labels))\n",
    "\n",
    "filenames=test_generator.filenames\n",
    "top1_results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":one_predictions})\n",
    "print(top1_results[ :10])\n",
    "\n",
    "################\n",
    "# Custom Accuracy    #\n",
    "################\n",
    "\n",
    "y_pred_raw = []\n",
    "\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    i = []\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(str(labels[index]))\n",
    "            i.append(labels[index])\n",
    "    predictions.append(\",\".join(l))\n",
    "    y_pred_raw.append(i)\n",
    "    \n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)\n",
    "print(results[ :10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1036
    },
    "colab_type": "code",
    "id": "Ye2OdeHLsDzg",
    "outputId": "c50863ad-88ce-4d22-c364-749134d7bd73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1795,   27],\n",
       "        [  18,   85]],\n",
       "\n",
       "       [[1858,    6],\n",
       "        [   4,   57]],\n",
       "\n",
       "       [[1760,   17],\n",
       "        [  22,  126]],\n",
       "\n",
       "       [[1814,   12],\n",
       "        [   7,   92]],\n",
       "\n",
       "       [[1762,   26],\n",
       "        [  22,  115]],\n",
       "\n",
       "       [[1897,    4],\n",
       "        [   9,   15]],\n",
       "\n",
       "       [[1603,  103],\n",
       "        [  88,  131]],\n",
       "\n",
       "       [[1698,  108],\n",
       "        [  50,   69]],\n",
       "\n",
       "       [[1680,  115],\n",
       "        [  37,   93]],\n",
       "\n",
       "       [[1526,  142],\n",
       "        [  70,  187]],\n",
       "\n",
       "       [[1874,   11],\n",
       "        [  22,   18]],\n",
       "\n",
       "       [[1734,   32],\n",
       "        [  37,  122]],\n",
       "\n",
       "       [[1790,   33],\n",
       "        [  34,   68]],\n",
       "\n",
       "       [[1834,   15],\n",
       "        [  16,   60]],\n",
       "\n",
       "       [[1826,   18],\n",
       "        [  20,   61]],\n",
       "\n",
       "       [[1917,    0],\n",
       "        [   8,    0]],\n",
       "\n",
       "       [[1766,   41],\n",
       "        [  24,   94]],\n",
       "\n",
       "       [[1780,   29],\n",
       "        [  43,   73]],\n",
       "\n",
       "       [[1733,   26],\n",
       "        [  57,  109]],\n",
       "\n",
       "       [[1527,  166],\n",
       "        [  85,  147]]])"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "mlb = MultiLabelBinarizer(classes=range(20))\n",
    "y_true = mlb.fit_transform(test_labels)\n",
    "y_pred = mlb.fit_transform(y_pred_raw)\n",
    "target = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "\n",
    "multilabel_confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 535
    },
    "colab_type": "code",
    "id": "r2yPITvg1iBO",
    "outputId": "178a078f-3af3-41d7-8e99-7ab732c29cc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.83      0.79       103\n",
      "           1       0.90      0.93      0.92        61\n",
      "           2       0.88      0.85      0.87       148\n",
      "           3       0.88      0.93      0.91        99\n",
      "           4       0.82      0.84      0.83       137\n",
      "           5       0.79      0.62      0.70        24\n",
      "           6       0.56      0.60      0.58       219\n",
      "           7       0.39      0.58      0.47       119\n",
      "           8       0.45      0.72      0.55       130\n",
      "           9       0.57      0.73      0.64       257\n",
      "          10       0.62      0.45      0.52        40\n",
      "          11       0.79      0.77      0.78       159\n",
      "          12       0.67      0.67      0.67       102\n",
      "          13       0.80      0.79      0.79        76\n",
      "          14       0.77      0.75      0.76        81\n",
      "          15       0.00      0.00      0.00         8\n",
      "          16       0.70      0.80      0.74       118\n",
      "          17       0.72      0.63      0.67       116\n",
      "          18       0.81      0.66      0.72       166\n",
      "          19       0.47      0.63      0.54       232\n",
      "\n",
      "   micro avg       0.65      0.72      0.68      2395\n",
      "   macro avg       0.67      0.69      0.67      2395\n",
      "weighted avg       0.67      0.72      0.69      2395\n",
      " samples avg       0.71      0.75      0.71      2395\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_true, y_pred, labels=range(20)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yP1duhwzn6fL"
   },
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 193
    },
    "colab_type": "code",
    "id": "mzBhvhKMNEgM",
    "outputId": "d8005284-5709-4ced-af43-25bbf50b0dcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "custom_model = load_model('densenet121_epoch_12_val_loss_0.1205.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tc58wko5VnbF"
   },
   "outputs": [],
   "source": [
    "# Linux: Create a  folder to contain val images.\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5JsDAaY5V1KW"
   },
   "outputs": [],
   "source": [
    "# Linux: Move the images folder into new folder.\n",
    "!cp -r ./val2014 ./output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "4SVJuTpzixpj",
    "outputId": "39679295-9ae6-4077-e1f7-f18c4f92870e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15516 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Prepare prediction.\n",
    "pred_generator = test_datagen.flow_from_directory(\n",
    "                            directory=r\"./output\",\n",
    "                            target_size=(224, 224),\n",
    "                            color_mode=\"rgb\",\n",
    "                            batch_size=1,\n",
    "                            class_mode=None,\n",
    "                            shuffle=False,\n",
    "                            seed=42\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "GQxgL_9erglk",
    "outputId": "3e7b5028-e89e-465c-f562-81e5378d51cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15516/15516 [==============================] - 768s 49ms/step\n"
     ]
    }
   ],
   "source": [
    "# Prediction for giving test set\n",
    "STEP_SIZE_PRED = pred_generator.n//pred_generator.batch_size\n",
    "\n",
    "pred_generator.reset()\n",
    "pred = custom_model.predict_generator(pred_generator,\n",
    "                steps=STEP_SIZE_PRED,\n",
    "                verbose=1)\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 207
    },
    "colab_type": "code",
    "id": "3l4sH77ObFy8",
    "outputId": "4f558e42-fd74-433e-9c0f-c181e3a99add"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Filename  Predictions\n",
      "0        0.jpg            2\n",
      "1        1.jpg            7\n",
      "6628     2.jpg            8\n",
      "7739     3.jpg           13\n",
      "8850     4.jpg           16\n",
      "9961     5.jpg           16\n",
      "11072    6.jpg            3\n",
      "12183    7.jpg            9\n",
      "13294    8.jpg            3\n",
      "14405    9.jpg            9\n"
     ]
    }
   ],
   "source": [
    "# Get the label and write into txt file. \n",
    "filenames = pred_generator.filenames\n",
    "results = pd.DataFrame({\"Filename\": [f.split('/')[1] for f in filenames],\n",
    "                      \"Predictions\": predictions,\n",
    "                      \"Numbers\": [int(f.split('/')[1].split('.')[0]) for f in filenames]})\n",
    "\n",
    "results.sort_values(\"Numbers\", inplace=True)\n",
    "results.drop([\"Numbers\"], axis=1, inplace=True)\n",
    "print(results[:10])\n",
    "results.to_csv(r'Predicted_labels.txt', header=None, index=None, sep='\\t')\n",
    "print(\"Writing into txt: Done\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "5329_ass2_densenet (1).ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
